{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import time \n",
    "import os\n",
    "import pathlib\n",
    "from torch import optim\n",
    "from torch.autograd import Variable \n",
    "from pathlib import Path\n",
    "from random import randint\n",
    "\n",
    "\n",
    "directory = r'C:\\Users\\savva\\OneDrive\\Desktop\\npy'\n",
    "patient_ID = ['2zbyXzYNKPwiPtjaA2L64o.npy','3hY7Mp7u9YPo1xMARSxLhc.npy','4h1dAuzg9rdrhyojwxUS26.npy']\n",
    "colums1 = ['time','end time']\n",
    "colums2 = ['time','end time','Reading 1']\n",
    "colums3 = ['time','end time','Reading 1','Reading 2']\n",
    "door_key = 0\n",
    "switch = 0\n",
    "pir_key = 0\n",
    "hidden_size = 2\n",
    "\n",
    "def Data_Loader(patient):\n",
    "    sensors_lst = []\n",
    "    column_names = []\n",
    "    for subdirectory in os.scandir(directory):\n",
    "        lock = False\n",
    "        for patients in os.scandir(subdirectory):\n",
    "            if str(pathlib.Path(patients)).endswith(patient_ID[0]):\n",
    "                if lock == False:\n",
    "                    column_names.append(str(os.path.basename(subdirectory)))\n",
    "                    lock == True                                              \n",
    "                sensors = np.load(pathlib.Path(patients))\n",
    "                sensors_lst.append(sensors)\n",
    "    sensors_pd = pd.DataFrame([sensors_lst],columns=column_names)\n",
    "    dataframe_lst = []\n",
    "    df = pd.DataFrame()\n",
    "    sensor_num = 0\n",
    "    Sensor_ID = column_names[sensor_num]\n",
    "    print(Sensor_ID)\n",
    "    for i in range(len(sensors_pd[Sensor_ID].loc[0])):\n",
    "        dataframe_lst.append(sensors_pd[Sensor_ID].loc[0][i])\n",
    "    if len(sensors_pd[Sensor_ID].loc[0][0]) == 2: \n",
    "        df = pd.DataFrame(dataframe_lst,columns = colums1)\n",
    "        df = df.drop(\"end time\", axis=1)\n",
    "    elif len(sensors_pd[Sensor_ID].loc[0][0]) == 3:    \n",
    "        df = pd.DataFrame(dataframe_lst,columns = colums2)\n",
    "        df = df.drop(\"end time\", axis=1)\n",
    "    elif len(sensors_pd[Sensor_ID].loc[0][0]) == 4:    \n",
    "        df = pd.DataFrame(dataframe_lst,columns = colums3)\n",
    "        df = df.drop(\"end time\", axis=1)\n",
    "    df['labels'] = 0\n",
    "    anomaly_lst = []\n",
    "    col_name = df.columns\n",
    "    col_len = len(df.columns)\n",
    "    return df\n",
    "\n",
    "\n",
    "def PIR_anomaly(self,n,id):\n",
    "    global pir_time\n",
    "    global pir_key\n",
    "    ranint = randint(0,19) # there are 20 locations\n",
    "    if pir_key == 0:\n",
    "        pir_time = self\n",
    "        s = [str(integer) for integer in pir_time]\n",
    "        a_string = \"\".join(s)\n",
    "        pir_time = int(a_string)\n",
    "        pir_key = 1\n",
    "    if pir_key == 1:\n",
    "        pir_time = pir_time + 60\n",
    "        return [pir_time] + [ranint]*(n - 2) + [1]\n",
    "\n",
    "        \n",
    "def anomaly_insertion(n,type,dataframe,id):\n",
    "    df = dataframe\n",
    "    anomaly_lst = []\n",
    "    col_name = df.columns\n",
    "    col_len = len(df.columns)\n",
    "    start_t = dataframe['time'].iloc[0]\n",
    "    end_t = dataframe['time'].iloc[-1]\n",
    "    for i in range(n):\n",
    "        random_timestamp = random.randint(start_t,end_t)\n",
    "        if type == 'zero':\n",
    "            zp_anomaly_lst = zero_anomaly([random_timestamp],col_len)\n",
    "        if type == 'random':\n",
    "            zp_anomaly_lst = random_anomaly([random_timestamp],col_len)\n",
    "        if type == 'door':\n",
    "            zp_anomaly_lst = door_anomaly([random_timestamp],col_len,id)\n",
    "        if type == 'PIR':\n",
    "            zp_anomaly_lst = PIR_anomaly([random_timestamp],col_len,id)\n",
    "        anomaly_lst.append(zp_anomaly_lst)\n",
    "    anomaly_df = pd.DataFrame(anomaly_lst,columns=col_name)\n",
    "    concat_df = pd.concat([dataframe,anomaly_df],ignore_index=True)\n",
    "    concat_df = concat_df.sort_values('time')\n",
    "    concat_df = concat_df.reset_index(drop=True)\n",
    "    return  concat_df\n",
    "\n",
    "\n",
    "dataT1 = Data_Loader(patient_ID[0])\n",
    "dataT2 = Data_Loader(patient_ID[1])\n",
    "df1 = Data_Loader(patient_ID[2])\n",
    "\n",
    "dataV = anomaly_insertion(120,'PIR',df1,id=1)\n",
    "\n",
    "dataT1 = dataT1.astype('float32')\n",
    "dataT2 = dataT2.astype('float32')\n",
    "dataV = dataV.astype('float32')\n",
    "\n",
    "train_data = [dataT1,dataT2]\n",
    "train_data = pd.concat(train_data)\n",
    "valid_data = dataV\n",
    "\n",
    "X_trainD = train_data.loc[:, train_data.columns != 'labels']\n",
    "X_valD = valid_data.loc[:, valid_data.columns != 'labels']\n",
    "Y_trainD = train_data.loc[:,'labels']\n",
    "Y_valD = valid_data.loc[:,'labels']\n",
    "\n",
    "X_train = torch.tensor(X_trainD.values).float()\n",
    "X_val =torch.tensor(X_valD.values).float()\n",
    "Y_train = torch.tensor(Y_trainD.values).float()\n",
    "Y_val = torch.tensor(Y_valD.values).float()\n",
    "\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, num_classes, input_size, hidden_size, num_layers, seq_length):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.num_classes = num_classes \n",
    "        self.num_layers = num_layers \n",
    "        self.input_size = input_size \n",
    "        self.hidden_size = hidden_size \n",
    "        self.seq_length = seq_length \n",
    "        self.lstm1 = nn.LSTM(input_size=input_size, hidden_size=hidden_size,\n",
    "                        num_layers=num_layers, batch_first=True) \n",
    "        self.lstm2 = nn.LSTM(input_size=input_size, hidden_size=hidden_size,\n",
    "                        num_layers=num_layers, batch_first=True)\n",
    "        self.fc_1 =  nn.Linear(hidden_size, 128) \n",
    "        self.fc = nn.Linear(128, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softmax = nn.Softmax()\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "    def forward(self,x):\n",
    "        x = x.unsqueeze(0)\n",
    "        h_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size)) \n",
    "        c_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size)) \n",
    "        output, (h1, c1) = self.lstm1(x, (h_0, c_0))\n",
    "        output, (h2, c2) = self.lstm1(x, (h1, c1))\n",
    "        hn = h2.view(-1, self.hidden_size) \n",
    "        out = self.relu(hn)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc_1(out) \n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc(out) \n",
    "        out = self.relu(out) \n",
    "        return out\n",
    "\n",
    "model = LSTM(2,hidden_size,4,1,2880)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 3e-3,momentum=0.9)\n",
    "criterion = nn.L1Loss()\n",
    "batch_size =1\n",
    "n_epochs =1\n",
    "permutation_train = torch.randperm(X_train.size()[0])\n",
    "permutation_val = torch.randperm(X_val.size()[0])\n",
    "anomalies = []\n",
    "mae_history = []\n",
    "history = []\n",
    "\n",
    "def Train_AD():\n",
    "    for epoch in range(n_epochs):\n",
    "        accuracy = 0\n",
    "        accuracy_history = []\n",
    "        timer_plot = []\n",
    "        for i in range(1,X_train.size()[0], batch_size):\n",
    "            optimizer.zero_grad()\n",
    "            indices = permutation_train[i:i+batch_size]\n",
    "            batch_x, batch_y = X_train[indices], Y_train[indices]\n",
    "            outputs = model.forward(batch_x)\n",
    "            loss = criterion(outputs,batch_y)\n",
    "            mae_history.append(loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            print(f\"-> Training for hidden size = \"+str(hidden_size)+\":   \"+str(i)+\"/\"+str(X_train.size()[0]), end = \"\\r\")        \n",
    "        reconstruction_error_threshold = max(mae_history)\n",
    "        print(\"the reconstruction error is:\" + str(reconstruction_error_threshold))\n",
    "        for a in range(1,X_val.size()[0], batch_size):\n",
    "            start_time = time.time() \n",
    "            indicesV = permutation_val[a:a+batch_size]\n",
    "            batch_x_val, batch_y_val = X_val[indicesV], Y_val[indicesV]\n",
    "            output = model.forward(batch_x_val)\n",
    "            loss = criterion(output,batch_y_val)\n",
    "            history.append(loss)\n",
    "            if loss > reconstruction_error_threshold:\n",
    "                anomalies.append(batch_x_val)\n",
    "            if(output == batch_y_val):\n",
    "                accuracy = accuracy +1\n",
    "                accuracy_history.append(accuracy/a)\n",
    "            time_elapsed = time.time() - start_time\n",
    "            timer_plot.append(1000*time_elapsed/len(X_val))\n",
    "            print(f\"-> Testing for hidden size = \"+str(hidden_size)+\":     \"+str(a)+\"/\"+str(X_val.size()[0]), end = \"\\r\")\n",
    "        print(f\"Finished for Hidden Size = \"+str(hidden_size)+\"                                             \")\n",
    "    print(len(anomalies))\n",
    "    return anomalies\n",
    "\n",
    "anomalies,accuracy = Train_AD()\n",
    "print(len(anomalies)) # for the program to work efficiently, the number of anomalies should be the same as the ones inserted.\n",
    "print(anomalies) # double check that they are indeed the correct ones.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c879ca8ca5a815bc56826a638592fabe51b21a9759afa2f7d6c7754aed8eb254"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
