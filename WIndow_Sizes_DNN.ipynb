{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\savva\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:96: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([1, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import time \n",
    "import os\n",
    "import pathlib\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import optim\n",
    "from torch.autograd import Variable \n",
    "from pathlib import Path\n",
    "from random import randint\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from statistics import mode, mean\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "directory = r\"C:\\Users\\savva\\OneDrive\\Desktop\\npy\"\n",
    "patient_ID = ['2zbyXzYNKPwiPtjaA2L64o.npy','3hY7Mp7u9YPo1xMARSxLhc.npy','4h1dAuzg9rdrhyojwxUS26.npy','BL3rTLVVUbXDyCxtWhSky6.npy','BqG6BCSqzJzxsiKHuMcrqr.npy','EzjmQuxceJzLATdtyUbDn8.npy',' GSzwDp5WGtabtzckHQw9Ya.npy',' HdozjhTxFXBhYAnKje524Q.npy','JEvSjBYo6KvDKHCGUnDNxm.npy']\n",
    "colums1 = ['time','end time']\n",
    "colums2 = ['time','end time','Reading 1']\n",
    "colums3 = ['time','end time','Reading 1','Reading 2']\n",
    "door_key = 0\n",
    "switch = 0\n",
    "pir_key = 0\n",
    "hidden_size = 2\n",
    "hidden_size\n",
    "global Sensor_ID\n",
    "sensor_num = 0\n",
    "def Data_Loader(patient):#,trimmed,x,y):\n",
    "    sensors_lst = []\n",
    "    global column_names\n",
    "    column_names = []\n",
    "    for subdirectory in os.scandir(directory):\n",
    "        lock = False\n",
    "        for patients in os.scandir(subdirectory):\n",
    "            if str(pathlib.Path(patients)).endswith(patient_ID[0]):\n",
    "                if lock == False:\n",
    "                    column_names.append(str(os.path.basename(subdirectory)))\n",
    "                    lock == True                                              \n",
    "                sensors = np.load(pathlib.Path(patients))\n",
    "                sensors_lst.append(sensors)\n",
    "    sensors_pd = pd.DataFrame([sensors_lst],columns=column_names)\n",
    "    dataframe_lst = []\n",
    "    df = pd.DataFrame()\n",
    "    Sensor_ID = column_names[sensor_num]\n",
    "    # print(Sensor_ID)\n",
    "    for i in range(len(sensors_pd[Sensor_ID].loc[0])):\n",
    "        dataframe_lst.append(sensors_pd[Sensor_ID].loc[0][i])\n",
    "    if len(sensors_pd[Sensor_ID].loc[0][0]) == 2: \n",
    "        df = pd.DataFrame(dataframe_lst,columns = colums1)\n",
    "        df = df.drop(\"end time\", axis=1)\n",
    "    elif len(sensors_pd[Sensor_ID].loc[0][0]) == 3:    \n",
    "        df = pd.DataFrame(dataframe_lst,columns = colums2)\n",
    "        df = df.drop(\"end time\", axis=1)\n",
    "    elif len(sensors_pd[Sensor_ID].loc[0][0]) == 4:    \n",
    "        df = pd.DataFrame(dataframe_lst,columns = colums3)\n",
    "        df = df.drop(\"end time\", axis=1)\n",
    "    df['labels'] = 0\n",
    "    time = df['time']\n",
    "    anomaly_lst = []\n",
    "    col_name = df.columns\n",
    "    col_len = len(df.columns)\n",
    "    delta_t = []\n",
    "    for i in range(0,len(df)-1):\n",
    "        delta = abs(df.iloc[i,0] - df.iloc[i+1,0])\n",
    "        delta_t.append(delta*100)\n",
    "        i = i+1\n",
    "    df['time delta'] = pd.Series(delta_t)\n",
    "    df.dropna(axis=1,inplace=False)\n",
    "\n",
    "\n",
    "\n",
    "    return df, Sensor_ID\n",
    "\n",
    "def activity_pir_anomaly(time,n,id): #spam\n",
    "    global pir_time\n",
    "    global pir_key\n",
    "    global switch\n",
    "    value = 5.\n",
    "    if pir_key == 0.0:\n",
    "        time_p = time\n",
    "        return [time_p,id,0,1.0] \n",
    "    if pir_key == 1.0:\n",
    "        time_p = time + 1.0\n",
    "        return [time_p] + [value] + [0] + [1.0]\n",
    "\n",
    "def ambient_temp_anomaly(time,n,id): # variance\n",
    "    global pir_time\n",
    "    global pir_key\n",
    "    variancen = randint(0.0,100.0)\n",
    "    sen_diff = 0.0\n",
    "    if pir_key == 0:\n",
    "        pir_time = time     \n",
    "        pir_key = 1\n",
    "    if pir_key == 1:\n",
    "        pir_time = pir_time +1.0\n",
    "        return [pir_time] + [id]+ [variancen]+ [0] + [1.0]\n",
    "\n",
    "def appliance_use_anomaly(time,n,id): # spam\n",
    "    global pir_time\n",
    "    global pir_key\n",
    "    intiger = 3.0\n",
    "    sen_diff = 0.0\n",
    "    if pir_key == 0:\n",
    "        pir_time = time     \n",
    "        pir_key = 1\n",
    "    if pir_key == 1:\n",
    "        pir_time = pir_time + 1.0\n",
    "        return [pir_time]  + [intiger]+ [0] + [1.0]\n",
    "\n",
    "def blood_pressure_anomaly(time,n,id): # small spike\n",
    "    global pir_time\n",
    "    global pir_key\n",
    "    varianc1 = randint(100.0,300.0)\n",
    "    varianc2 = randint(80.0,200.0)\n",
    "    sen_diff = 0.0\n",
    "    if pir_key == 0:\n",
    "        pir_time = time     \n",
    "        pir_key = 1\n",
    "    if pir_key == 1:\n",
    "        pir_time = pir_time +1.0\n",
    "        return [pir_time] + [varianc1]+ [varianc2]+ [0] + [1.0]\n",
    "\n",
    "def body_mass_index_anomaly(time,n,id): # variance\n",
    "    global pir_time\n",
    "    global pir_key\n",
    "    variancen = randint(0.0,30.0)\n",
    "    if pir_key == 0:\n",
    "        pir_time = time     \n",
    "        pir_key = 1\n",
    "    if pir_key == 1:\n",
    "        pir_time = pir_time +1.0\n",
    "        return [pir_time] + [variancen]+ [0] + [1.0]\n",
    "\n",
    "def body_temperature_anomaly(time,n,id): # #Variance\n",
    "    global pir_time\n",
    "    global pir_key\n",
    "    variancen = randint(0.0,50.0)\n",
    "    sen_diff = 0.0\n",
    "    if pir_key == 0:\n",
    "        pir_time = time     \n",
    "        pir_key = 1\n",
    "    if pir_key == 1:\n",
    "        pir_time = pir_time + 1.0\n",
    "        return [pir_time] + [variancen]+ [0] + [1.0]\n",
    "\n",
    "def body_weight_anomaly(time,n,id): #Spike\n",
    "    global pir_time\n",
    "    global pir_key\n",
    "    spike = randint(500.0,600.0)\n",
    "    spiketime = randint(8000000,9000000)\n",
    "    sen_diff = 0.0\n",
    "    if pir_key == 0:\n",
    "        pir_time = time     \n",
    "        pir_key = 1\n",
    "    if pir_key == 1:\n",
    "        pir_time = pir_time + 1.0\n",
    "        return [pir_time] + [spike]+ [0] + [1.0]\n",
    "\n",
    "def door_sensor_anomaly(time,n,value):#create\n",
    "    global pir_time\n",
    "    global pir_key\n",
    "    if pir_key == 0.0:\n",
    "        time_p = time\n",
    "        return [time_p,id,value,0,1.0] \n",
    "    if pir_key == 1.0:\n",
    "        time_p = time + 1.0\n",
    "        return [time_p] + [id] + [value] + [0] + [1.0]\n",
    "\n",
    "def heart_rate_anomaly(time,n,id): #spike\n",
    "    global pir_time\n",
    "    global pir_key\n",
    "    spike = randint(300.0,400.0)\n",
    "    spiketime = randint(0,10000)\n",
    "    sen_diff = 0.0\n",
    "    if pir_key == 0:\n",
    "        pir_time = time     \n",
    "        pir_key = 1\n",
    "    if pir_key == 1:\n",
    "        pir_time = pir_time + 1.0\n",
    "        return [pir_time] + [spike]+ [0] + [1.0]\n",
    "\n",
    "def light_anomaly(time,n,id): #spike\n",
    "    global pir_time\n",
    "    global pir_key\n",
    "    variancen = randint(0.0,10000.0)\n",
    "    delta_t = randint(0,100)\n",
    "    if pir_key == 0:\n",
    "        pir_time = time     \n",
    "        pir_key = 1\n",
    "    if pir_key == 1:\n",
    "        pir_time = pir_time +1.0\n",
    "        return [pir_time] + [id]+ [variancen]+ [0] + [1.0]\n",
    "\n",
    "def oxygen_saturation_anomaly(time,n,id): # variance\n",
    "    global pir_time\n",
    "    global pir_key\n",
    "    variancen = randint(0.0,200.0)\n",
    "    sen_diff = 0.0\n",
    "    if pir_key == 0:\n",
    "        pir_time = time     \n",
    "        pir_key = 1\n",
    "    if pir_key == 1:\n",
    "        pir_time = pir_time +1.0\n",
    "        return [pir_time] + [variancen] + [0] + [1.0]\n",
    "\n",
    "def skin_temperature_anomaly(time,n,id): #spike\n",
    "    global pir_time\n",
    "    global pir_key\n",
    "    variancen = randint(0.0,1000.0)\n",
    "    delta_t = randint(0,100)\n",
    "    if pir_key == 0:\n",
    "        pir_time = time     \n",
    "        pir_key = 1\n",
    "    if pir_key == 1:\n",
    "        pir_time = pir_time +20.0\n",
    "        return [pir_time] + [variancen]+ [0] + [1.0]\n",
    "\n",
    "def sleep_event_anomaly(time,n,value):#create\n",
    "    global pir_time\n",
    "    global pir_key\n",
    "    if pir_key == 0.0:\n",
    "        time_p = time\n",
    "        return [time_p,value,0,1.0] \n",
    "    if pir_key == 1.0:\n",
    "        time_p = time + 10.0\n",
    "        return [time_p] + [value] + [0] + [1.0]\n",
    "\n",
    "def sleep_mat_heart_rate_anomaly(time,n,id): #spike\n",
    "    global pir_time\n",
    "    global pir_key\n",
    "    variancen = randint(100.0,1000.0)\n",
    "    delta_t = randint(0,10000)\n",
    "    if pir_key == 0:\n",
    "        pir_time = time     \n",
    "        pir_key = 1\n",
    "    if pir_key == 1:\n",
    "        pir_time = pir_time + delta_t \n",
    "        return [pir_time] + [variancen]+ [0] + [1.0]\n",
    "\n",
    "def sleep_mat_respiratory_rate_anomaly(time,n,id): #spike\n",
    "    global pir_time\n",
    "    global pir_key\n",
    "    variancen = randint(25.0,100.0)\n",
    "    delta_t = randint(0,10000)\n",
    "    if pir_key == 0:\n",
    "        pir_time = time     \n",
    "        pir_key = 1\n",
    "    if pir_key == 1:\n",
    "        pir_time = pir_time + delta_t \n",
    "        return [pir_time] + [variancen]+ [0] + [1.0]\n",
    "\n",
    "def sleep_mat_snoring_rate_anomaly(time,n,value):#create\n",
    "    global pir_time\n",
    "    global pir_key\n",
    "    if pir_key == 0.0:\n",
    "        time_p = time\n",
    "        return [time_p,value,0,1.0] \n",
    "    if pir_key == 1.0:\n",
    "        time_p = time + 10.0\n",
    "        return [time_p] + [value] + [0] + [1.0]\n",
    "\n",
    "def sleep_mat_state_anomaly(time,n,value):#create\n",
    "    global pir_time\n",
    "    global pir_key\n",
    "    if pir_key == 0.0:\n",
    "        time_p = time\n",
    "        return [time_p,value,0,1.0] \n",
    "    if pir_key == 1.0:\n",
    "        time_p = time + 1.0\n",
    "        return [time_p] + [value] + [0] + [1.0]\n",
    "\n",
    "def anomaly_insertion(n,type,dataframe,id):\n",
    "    df = dataframe\n",
    "    anomaly_lst = []\n",
    "    col_name = df.columns\n",
    "    col_len = len(df.columns)\n",
    "    start_t = min(dataframe['time'])\n",
    "    end_t = max(dataframe['time'])\n",
    "    value = 0\n",
    "    for i in range(n):\n",
    "        random_timestamp = random.randint(start_t,end_t)\n",
    "        value = i%2 #for the create\n",
    "        if type == 'activity_pir':\n",
    "            zp_anomaly_lst= activity_pir_anomaly(random_timestamp,col_len,id)   \n",
    "        if type == 'ambient_temperature':\n",
    "            zp_anomaly_lst= ambient_temp_anomaly(random_timestamp,col_len,id)  \n",
    "        if type == 'appliance_use':\n",
    "            zp_anomaly_lst= appliance_use_anomaly(random_timestamp,col_len,id)   \n",
    "        if type == 'blood_pressure':\n",
    "            zp_anomaly_lst= blood_pressure_anomaly(random_timestamp,col_len,id) \n",
    "        if type == 'body_mass_index':\n",
    "            zp_anomaly_lst= body_mass_index_anomaly(random_timestamp,col_len,id) \n",
    "        if type == 'body_temperature':\n",
    "            zp_anomaly_lst= body_temperature_anomaly(random_timestamp,col_len,id)      \n",
    "        if type == 'body_weight':\n",
    "            zp_anomaly_lst= body_weight_anomaly(random_timestamp,col_len,id) \n",
    "        if type == 'door_sensor':\n",
    "            zp_anomaly_lst= door_sensor_anomaly(random_timestamp,col_len,id) \n",
    "        if type == 'heart_rate':\n",
    "            zp_anomaly_lst= heart_rate_anomaly(random_timestamp,col_len,id) \n",
    "        if type == 'light':\n",
    "            zp_anomaly_lst= light_anomaly(random_timestamp,col_len,id)          \n",
    "        if type == 'oxygen_saturation':\n",
    "            zp_anomaly_lst= oxygen_saturation_anomaly(random_timestamp,col_len,id)          \n",
    "        if type == 'skin_temperature':\n",
    "            zp_anomaly_lst= skin_temperature_anomaly(random_timestamp,col_len,id) \n",
    "        if type == 'sleep_event':\n",
    "            zp_anomaly_lst= sleep_event_anomaly(random_timestamp,col_len,value) \n",
    "        if type == 'sleep_mat_heart_rate':\n",
    "            zp_anomaly_lst= sleep_mat_heart_rate_anomaly(random_timestamp,col_len,id)    \n",
    "        if type == 'sleep_mat_respiratory_rate':\n",
    "            zp_anomaly_lst= sleep_mat_respiratory_rate_anomaly(random_timestamp,col_len,id)  \n",
    "        if type == 'sleep_mat_snoring':\n",
    "            zp_anomaly_lst= sleep_mat_snoring_rate_anomaly(random_timestamp,col_len,value) \n",
    "        if type == 'sleep_mat_state':\n",
    "            zp_anomaly_lst= sleep_mat_state_anomaly(random_timestamp,col_len,value)                  \n",
    "        anomaly_lst.append(zp_anomaly_lst)\n",
    "    anomaly_df = pd.DataFrame(anomaly_lst,columns=col_name)\n",
    "    concat_df = pd.concat([dataframe,anomaly_df],ignore_index=True)\n",
    "    concat_df = concat_df.reset_index(drop=True)\n",
    "    return  concat_df,anomaly_lst\n",
    "\n",
    "def Time_Selection(dataframe,window_h,window_m,length_h,length_m):\n",
    "    rand_time_date = randint(int(min(dataframe['time'])),int(max(dataframe['time'])))\n",
    "    init_time = datetime.datetime(2000, 1, 1, window_h, window_m) #date does not matter\n",
    "    displ_time = datetime.datetime(2000, 1, 1,length_h,length_m) \n",
    "    lst = []\n",
    "    time_lst = []\n",
    "    lock = 0\n",
    "    for i in range(len(dataframe)):        \n",
    "        curr_time = dataframe['time'].loc[i]\n",
    "        curr_time = pd.to_datetime(curr_time,utc = True,unit = 's')    \n",
    "        if init_time.time() < curr_time.time() < displ_time.time():\n",
    "            lst.append(i)\n",
    "            time_lst.append(curr_time.time())\n",
    "            lock = 1\n",
    "        else: \n",
    "            if lock == 1:    \n",
    "                break\n",
    "            else: pass            \n",
    "    return lst,time_lst\n",
    "\n",
    "def Data_Preprocessing(valid_percentile,time_h,time_m):\n",
    "\n",
    "    df,Sensor_ID = Data_Loader(patient_ID[7])\n",
    "    buss,time_lst = Time_Selection(df,0,0,time_h,time_m)\n",
    "    low_t = min(buss)\n",
    "    max_t = max(buss)\n",
    "    train_data =  df[low_t:max_t]\n",
    "    size_df = len(train_data)\n",
    "    splitsize = int(valid_percentile*size_df)\n",
    "    valid_data = df[max_t:max_t+splitsize].astype('float32')\n",
    "    train_data =  df[low_t:max_t].astype('float32')\n",
    "\n",
    "    n_t = len(valid_data)\n",
    "    n = int(n_t/4)\n",
    "    print(n)\n",
    "    valid_data,anom_lst = anomaly_insertion(n,Sensor_ID,valid_data,5.0)\n",
    "    X_trainD = train_data.loc[:, train_data.columns != 'labels']\n",
    "    X_valD = valid_data.loc[:, valid_data.columns != 'labels']\n",
    "    Y_trainD = train_data.loc[:,'labels']\n",
    "    Y_valD = valid_data.loc[:,'labels']\n",
    "\n",
    "    X_train = torch.tensor(X_trainD.values).float()\n",
    "    X_val =torch.tensor(X_valD.values).float()\n",
    "    Y_train = torch.tensor(Y_trainD.values).float()\n",
    "    Y_val = torch.tensor(Y_valD.values).float()\n",
    "\n",
    "    Y_tensor = Y_train.clone().detach()\n",
    "    new_shape = (len(Y_tensor), 1)\n",
    "    Y_train = Y_tensor.view(new_shape)\n",
    "\n",
    "    Y_tensor = Y_val.clone().detach()\n",
    "    new_shape = (len(Y_tensor), 1)\n",
    "    Y_val = Y_tensor.view(new_shape)\n",
    "\n",
    "    torch.flatten(X_train)\n",
    "    torch.flatten(Y_train)\n",
    "    torch.flatten(X_val)\n",
    "    torch.flatten(Y_val)\n",
    "\n",
    "    return X_train,Y_train,X_val,Y_val,train_data,valid_data,time_lst,anom_lst,Sensor_ID\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(size_mat, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 1024)\n",
    "        self.fc3 = nn.Linear(1024, 512)        \n",
    "        self.fc4 = nn.Linear(512, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "def Train_AD(valid_percentile,time_h,time_m):\n",
    "    X_train,Y_train,X_val,Y_val,train_data,valid_data,time_lst,anom_lst,Sensor_ID = Data_Preprocessing(valid_percentile,time_h,time_m)\n",
    "    global size_mat\n",
    "    size_mat = len(X_train[0]-2)\n",
    "    model = Net()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = 3e-5)\n",
    "    criterion = nn.L1Loss()\n",
    "    batch_size = 1\n",
    "    n_epochs = 100\n",
    "    permutation_train = torch.randperm(X_train.size()[0])\n",
    "    permutation_val = torch.randperm(X_val.size()[0])\n",
    "    for epoch in range(n_epochs):\n",
    "        anomalies = []\n",
    "        train_loss = []\n",
    "        valid_loss = []\n",
    "        accuracy = 0\n",
    "        accuracy_history = []\n",
    "        timer_plot = []\n",
    "        for i in range(0,len(train_data), batch_size):\n",
    "            optimizer.zero_grad()\n",
    "            indices = permutation_train[i:i+batch_size]\n",
    "            batch_x, batch_y = X_train[indices], Y_train[indices]\n",
    "            outputs = model.forward(batch_x)\n",
    "            loss = criterion(outputs,batch_y)\n",
    "            train_loss.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        threshold = mean(train_loss)*1.5\n",
    "        for a in range(0,X_val.size()[0], batch_size):\n",
    "            indicesV = permutation_val[a:a+batch_size]\n",
    "            batch_x_val, batch_y_val = X_val[indicesV], Y_val[indicesV]\n",
    "            output = model.forward(batch_x_val)\n",
    "            pred = torch.max(output,1)[1]\n",
    "            loss = criterion(output,batch_y_val)\n",
    "            valid_loss.append(loss.item())\n",
    "            if loss.item() >= threshold:\n",
    "                anomalies.append(batch_x_val)\n",
    "    return anomalies,train_loss,valid_loss,time_lst,Sensor_ID\n",
    "\n",
    "def Main(valid_percentile,time_h,time_m):\n",
    "    anomalies,tL,vL,times,Sensor_ID = Train_AD(valid_percentile,time_h,time_m)\n",
    "    counter = 0\n",
    "    size = len(anomalies[0])\n",
    "    for i in range(len(anomalies)):\n",
    "        x = anomalies[i].numpy()\n",
    "        if x[0][size]==1.0:\n",
    "            counter = counter+1\n",
    "    correct = counter\n",
    "    fake_positive = len(anomalies) - correct\n",
    "    print('')\n",
    "    print(str(Sensor_ID)+',  For ' +str(time_h)+ ':'+str(time_m)+'  validation percentile: '+str(valid_percentile))\n",
    "    print('Correctly Identified Anomalies: ' + str(correct))\n",
    "    print('Fake Positives: '+ str(fake_positive))\n",
    "\n",
    "    return Sensor_ID,times[0],correct,fake_positive\n",
    "\n",
    "periods = [[12,0],[6,0],[2,0]]\n",
    "valid_percentile = [0.2]\n",
    "total_results = []\n",
    "\n",
    "for a in range(22):\n",
    "    try:\n",
    "        sensor_num = a\n",
    "        results = []\n",
    "        for i in range(len(periods)):\n",
    "            try:\n",
    "                Sensor_ID,time,correct,fake_positive = Main(valid_percentile[0],periods[i][0],periods[i][1])\n",
    "                results.append([Sensor_ID,periods[i][0],correct,fake_positive])\n",
    "            except:\n",
    "\n",
    "                pass\n",
    "        if len(results)>0:\n",
    "            total_results.append(results)\n",
    "        else: pass\n",
    "    except:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c879ca8ca5a815bc56826a638592fabe51b21a9759afa2f7d6c7754aed8eb254"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
